{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Field Networks\n",
    "\n",
    "Implementation of shape classification demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anim\n",
    "import tensorflow.compat.v1 as tf\n",
    "import random\n",
    "from math import pi, sqrt\n",
    "import tensorfieldnetworks.layers as layers\n",
    "import tensorfieldnetworks.utils as utils\n",
    "from tensorfieldnetworks.utils import FLOAT_TYPE\n",
    "\n",
    "tetris = [[(0, 0, 0), (0, 0, 1), (1, 0, 0), (1, 1, 0)],  # chiral_shape_1\n",
    "          [(0, 0, 0), (0, 0, 1), (1, 0, 0), (1, -1, 0)], # chiral_shape_2\n",
    "          [(0, 0, 0), (1, 0, 0), (0, 1, 0), (1, 1, 0)],  # square\n",
    "          [(0, 0, 0), (0, 0, 1), (0, 0, 2), (0, 0, 3)],  # line\n",
    "          [(0, 0, 0), (0, 0, 1), (0, 1, 0), (1, 0, 0)],  # corner\n",
    "          [(0, 0, 0), (0, 0, 1), (0, 0, 2), (0, 1, 0)],  # T\n",
    "          [(0, 0, 0), (0, 0, 1), (0, 0, 2), (0, 1, 1)],  # zigzag\n",
    "          [(0, 0, 0), (1, 0, 0), (1, 1, 0), (2, 1, 0)]]  # L\n",
    "\n",
    "dataset = [np.array(points_) for points_ in tetris]\n",
    "num_classes = len(dataset)\n",
    "\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radial basis functions\n",
    "rbf_low = 0.0\n",
    "rbf_high = 3.5\n",
    "rbf_count = 4\n",
    "rbf_spacing = (rbf_high - rbf_low) / rbf_count\n",
    "centers = tf.cast(tf.lin_space(rbf_low, rbf_high, rbf_count), FLOAT_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-f328017655d0>:46: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# r : [N, 3]\n",
    "r = tf.placeholder(FLOAT_TYPE, shape=(4, 3))\n",
    "\n",
    "# rij : [N, N, 3]\n",
    "rij = utils.difference_matrix(r)\n",
    "\n",
    "# dij : [N, N]\n",
    "dij = utils.distance_matrix(r)\n",
    "\n",
    "# rbf : [N, N, rbf_count]\n",
    "gamma = 1. / rbf_spacing\n",
    "rbf = tf.exp(-gamma * tf.square(tf.expand_dims(dij, axis=-1) - centers))\n",
    "\n",
    "layer_dims = [1, 4, 4, 4]\n",
    "num_layers = len(layer_dims) - 1\n",
    "\n",
    "# embed : [N, layer1_dim, 1]\n",
    "with tf.variable_scope(None, \"embed\"):\n",
    "    embed = layers.self_interaction_layer_without_biases(tf.ones(shape=(4, 1, 1)), layer_dims[0])\n",
    "\n",
    "input_tensor_list = {0: [embed]}\n",
    "\n",
    "for layer, layer_dim in enumerate(layer_dims[1:]):\n",
    "    with tf.variable_scope(None, 'layer' + str(layer), values=[input_tensor_list]):\n",
    "        input_tensor_list = layers.convolution(input_tensor_list, rbf, rij)\n",
    "        input_tensor_list = layers.concatenation(input_tensor_list)\n",
    "        input_tensor_list = layers.self_interaction(input_tensor_list, layer_dim)\n",
    "        input_tensor_list = layers.nonlinearity(input_tensor_list)\n",
    "\n",
    "tfn_scalars = input_tensor_list[0][0]\n",
    "tfn_output_shape = tfn_scalars.get_shape().as_list()\n",
    "tfn_output = tf.reduce_mean(tf.squeeze(tfn_scalars), axis=0)\n",
    "fully_connected_layer = tf.get_variable('fully_connected_weights', \n",
    "                                        [tfn_output_shape[-2], len(dataset)], dtype=FLOAT_TYPE)\n",
    "output_biases = tf.get_variable('output_biases', [len(dataset)], dtype=FLOAT_TYPE)\n",
    "\n",
    "# output : [num_classes]\n",
    "output = tf.einsum('xy,x->y', fully_connected_layer, tfn_output) + output_biases\n",
    "\n",
    "tf_label = tf.placeholder(tf.int32)\n",
    "\n",
    "# truth : [num_classes]\n",
    "truth = tf.one_hot(tf_label, num_classes)\n",
    "\n",
    "# loss : []\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(labels=truth, logits=output)\n",
    "\n",
    "optim = tf.train.AdamOptimizer(learning_rate=1.e-3)\n",
    "\n",
    "train_op = optim.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: validation loss = 2.222\n",
      "Epoch 100: validation loss = 1.545\n",
      "Epoch 200: validation loss = 0.482\n",
      "Epoch 300: validation loss = 0.015\n",
      "Epoch 400: validation loss = 0.002\n",
      "Epoch 500: validation loss = 0.001\n",
      "Epoch 600: validation loss = 0.000\n",
      "Epoch 700: validation loss = 0.000\n",
      "Epoch 800: validation loss = 0.000\n",
      "Epoch 900: validation loss = 0.000\n",
      "Epoch 1000: validation loss = 0.000\n",
      "Epoch 1100: validation loss = 0.000\n",
      "Epoch 1200: validation loss = 0.000\n",
      "Epoch 1300: validation loss = 0.000\n",
      "Epoch 1400: validation loss = 0.000\n",
      "Epoch 1500: validation loss = 0.000\n",
      "Epoch 1600: validation loss = 0.000\n",
      "Epoch 1700: validation loss = 0.000\n",
      "Epoch 1800: validation loss = 0.000\n",
      "Epoch 1900: validation loss = 0.000\n",
      "Epoch 2000: validation loss = 0.000\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 2001\n",
    "print_freq = 100\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# training\n",
    "for epoch in range(max_epochs):    \n",
    "    loss_sum = 0.\n",
    "    for label, shape in enumerate(dataset):\n",
    "        loss_value, _ = sess.run([loss, train_op], feed_dict={r: shape, tf_label: label})\n",
    "        loss_sum += loss_value\n",
    "        \n",
    "    if epoch % print_freq == 0:\n",
    "        print(\"Epoch %d: validation loss = %.3f\" % (epoch, loss_sum / len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState()\n",
    "test_set_size = 25\n",
    "predictions = [list() for i in range(len(dataset))]\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "for i in range(test_set_size):\n",
    "    for label, shape in enumerate(dataset):\n",
    "        rotation = utils.random_rotation_matrix(rng)\n",
    "        rotated_shape = np.dot(shape, rotation)\n",
    "        translation = np.expand_dims(np.random.uniform(low=-3., high=3., size=(3)), axis=0)\n",
    "        translated_shape = rotated_shape + translation\n",
    "        output_label = sess.run(tf.argmax(output), \n",
    "                                feed_dict={r: rotated_shape, tf_label: label})\n",
    "        total_predictions += 1\n",
    "        if output_label == label:\n",
    "            correct_predictions += 1\n",
    "print('Test accuracy: %f' % (float(correct_predictions) / total_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
